{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babac574",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly.\n",
    "> That's fine.\n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40754d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-15 01:35:01--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘data.csv’\n",
      "\n",
      "data.csv            100%[===================>]  78.98K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2025-10-15 01:35:01 (13.4 MB/s) - ‘data.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv -O data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2320a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1462, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e7a646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d31f4",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For categorical features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b7c01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5bc61ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_courses_viewed', 'annual_income', 'interaction_count',\n",
       "       'lead_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = df.select_dtypes(include=['int64', 'float64'])\n",
    "numerical = numerical.drop(columns=['converted'])\n",
    "numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb18cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_source', 'industry', 'employment_status', 'location'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = df.select_dtypes(include=['object'])\n",
    "categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d33d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical.columns] = df[numerical.columns].fillna(0.0)\n",
    "df[categorical.columns] = df[categorical.columns].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a321af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical.columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9f947e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8127d5",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n",
    "\n",
    "- `NA`\n",
    "- `technology`\n",
    "- `healthcare`\n",
    "- `retail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56f0880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "na               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb60dcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3cbf1",
   "metadata": {},
   "source": [
    "Answer 1 = retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4d948",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- `annual_income` and `interaction_count`\n",
    "\n",
    "Only consider the pairs above when answering this question.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c9295af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.027</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                     1.000          0.010   \n",
       "annual_income                                0.010          1.000   \n",
       "interaction_count                           -0.024          0.027   \n",
       "lead_score                                  -0.005          0.016   \n",
       "\n",
       "                          interaction_count  lead_score  \n",
       "number_of_courses_viewed             -0.024      -0.005  \n",
       "annual_income                         0.027       0.016  \n",
       "interaction_count                     1.000       0.010  \n",
       "lead_score                            0.010       1.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cormatrix = df[numerical.columns].corr().round(3)\n",
    "cormatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373b438",
   "metadata": {},
   "source": [
    "interaction_count and lead_score = 0.010\n",
    "\n",
    "number_of_courses_viewed and lead_score = -0.005\n",
    "\n",
    "number_of_courses_viewed and interaction_count = -0.024\n",
    "\n",
    "annual_income and interaction_count = 0.027\n",
    "\n",
    "Answer: annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41b3ea",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "- Make sure that the target value `converted` is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4ca490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b354dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a30f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 293, 293)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val), len(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1112fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_full_train = df_full_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "619868c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values\n",
    "y_full_train = df_full_train['converted'].values\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']\n",
    "del df_full_train['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5341f055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>0</td>\n",
       "      <td>58472.0</td>\n",
       "      <td>student</td>\n",
       "      <td>middle_east</td>\n",
       "      <td>5</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>3</td>\n",
       "      <td>71738.0</td>\n",
       "      <td>student</td>\n",
       "      <td>middle_east</td>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>technology</td>\n",
       "      <td>3</td>\n",
       "      <td>81973.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>74956.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>retail</td>\n",
       "      <td>3</td>\n",
       "      <td>59335.0</td>\n",
       "      <td>student</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
       "0        paid_ads         retail                         0        58472.0   \n",
       "1  organic_search  manufacturing                         3        71738.0   \n",
       "2        paid_ads     technology                         3        81973.0   \n",
       "3              na     technology                         1        74956.0   \n",
       "4  organic_search         retail                         3        59335.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  \n",
       "0           student    middle_east                  5        0.03  \n",
       "1           student    middle_east                  6        0.77  \n",
       "2          employed  north_america                  2        0.59  \n",
       "3          employed         europe                  3        0.34  \n",
       "4           student      australia                  1        0.98  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2d1c2",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- `industry`\n",
    "- `location`\n",
    "- `lead_source`\n",
    "- `employment_status`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b603929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03baa67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry 0.01\n",
      "location 0.0\n",
      "lead_source 0.04\n",
      "employment_status 0.01\n"
     ]
    }
   ],
   "source": [
    "for col in ('industry','location','lead_source','employment_status'):\n",
    "    print(col, round(mutual_info_score(df_train[col], y_train),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7bbb9",
   "metadata": {},
   "source": [
    "Answer: lead_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b712d24",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- 0.84\n",
    "- 0.94\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e5650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb4bcd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 31)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f51d5ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "539eb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79b094d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.06914728027832559),\n",
       " array([-1.77843866e-05,  3.39095225e-02, -1.47154423e-02,  2.66248432e-03,\n",
       "         1.15238518e-02, -1.02527697e-01,  4.93604222e-02, -2.01258344e-02,\n",
       "        -1.34214865e-02, -3.00232200e-03, -2.48510995e-02, -9.25991830e-03,\n",
       "        -3.17957304e-02, -1.60513114e-02,  3.11339155e-01,  5.12012528e-02,\n",
       "        -1.20346284e-02,  2.01511698e-02, -1.16021521e-02, -1.15251880e-01,\n",
       "         7.95303436e-02, -2.99401329e-02, -1.14296944e-02, -1.12457415e-02,\n",
       "        -5.59987025e-03,  8.26402635e-03,  5.58598769e-03,  3.95843295e-03,\n",
       "        -3.33967159e-02, -2.52837052e-02,  4.53752887e-01]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42, C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "model.intercept_[0], model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b45500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "convert_predict = (y_pred >= 0.5).astype(int)\n",
    "round((convert_predict == y_val).mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22af9141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6996587030716723)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(convert_predict == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73eb88",
   "metadata": {},
   "source": [
    "Answer: Accuracy = 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b618043",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `'industry'`\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "\n",
    "> **Note**: The difference doesn't have to be positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "743cafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, y_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce474ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_source', 'industry', 'employment_status', 'location']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "categorical_names = categorical.columns.tolist()\n",
    "categorical_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_source',\n",
       " 'employment_status',\n",
       " 'location',\n",
       " 'number_of_courses_viewed',\n",
       " 'annual_income',\n",
       " 'interaction_count',\n",
       " 'lead_score']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subset_names = categorical.columns.tolist() + numerical.columns.tolist()\n",
    "subset_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eeeae128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.025665\n",
       "employment_status    0.013258\n",
       "industry             0.011685\n",
       "location             0.002253\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = df_full_train[categorical_names].apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e59e8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModelWithout(colname):\n",
    "    subset_names = categorical.columns.tolist() + numerical.columns.tolist()\n",
    "    subset_names.remove(colname)\n",
    "    print (subset_names)\n",
    "    train_dict = df_train[subset_names].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "    model = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42, C=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "    val_dict = df_val[subset_names].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    convert_predict = (y_pred >= 0.5).astype(int)\n",
    "    return (convert_predict == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a22f372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(series, Cval):\n",
    "    train_dict = series.to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "    model = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42, C=Cval)\n",
    "    model.fit(X_train, y_train)\n",
    "    val_dict = df_val[subset_names].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    convert_predict = (y_pred >= 0.5).astype(int)\n",
    "    return (convert_predict == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d5b34d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead_source', 'employment_status', 'location', 'number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "industry 0.6996587030716723\n",
      "['lead_source', 'industry', 'location', 'number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "employment_status 0.6962457337883959\n",
      "['lead_source', 'industry', 'employment_status', 'location', 'number_of_courses_viewed', 'annual_income', 'interaction_count']\n",
      "lead_score 0.7064846416382252\n"
     ]
    }
   ],
   "source": [
    "for col in ('industry','employment_status','lead_score'):\n",
    "    print(col, TrainModelWithout(col))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d9189",
   "metadata": {},
   "source": [
    "Answer: Least difference = without industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c70570b",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d411874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.689419795221843\n",
      "0.1 0.6996587030716723\n",
      "1 0.6996587030716723\n",
      "10 0.6996587030716723\n",
      "100 0.6996587030716723\n"
     ]
    }
   ],
   "source": [
    "for c in (0.01, 0.1, 1, 10,100):\n",
    "    print(c, TrainModel(df_train, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6ec71",
   "metadata": {},
   "source": [
    "Answer C = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4395c",
   "metadata": {},
   "source": [
    "\n",
    "## Submit the results\n",
    "\n",
    "- Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw03\n",
    "- If your answer doesn't match options exactly, select the closest one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
